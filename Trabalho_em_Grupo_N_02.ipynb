{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lima-breno/deep_learning_and_neural_networks/blob/main/Trabalho_em_Grupo_N_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRABALHO N.02**\n"
      ],
      "metadata": {
        "id": "Q3lIvK9P4QsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Descreva sucintamente o funcionamento da normalização em lote (batch normalization)."
      ],
      "metadata": {
        "id": "gr9NolsK4mvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A normalização de lote é uma técnica que normaliza as funções de ativação de uma camada em um mini-lote durante o treinamento de redes neurais profundas.\n",
        "\n",
        "Assim, ao invés de calcular um gradiente sobre todo os conjuntos de dados, utiliza-se um subconjunto de tamanho fixo de amostras de dados denominado minibatch.\n",
        "\n",
        "Ao utilizarmos a normalização em lote diminuimos a mudança de covariáveis internas ao processo de treinamento, tornando as entradas das camadassubsequentes mais estáveis e consistentes. O que permite uma convergência mais rápida com taxas de aprendizado mais altas e torna o modelo menos sensível às escolhas de inicialização. Além de introduzir um efeito de regularização que ajuda a evitar o ajuste excessivo, reduzindo a dependencia do modelo de padrões de ativação específicos.\n",
        "\n"
      ],
      "metadata": {
        "id": "pdZ3-4na4mq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Descreva sucintamente o funcionamento da regularização por dropout."
      ],
      "metadata": {
        "id": "Te4c-CPb4mnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Dropout é uma técnica de regularização de modelos, cuja ideia principal consiste em descartar aleatoriamente unidades (neurônios), juntamente com suas conexões, durante o treinamento da rede neural.\n",
        "\n",
        "Em termos práticos, a cada iteração, em determinado passo, algumas unidades são desligadas aleatoriamente, e os cálculos são realizados apenas com as que permanecem ativas.\n",
        "\n",
        "Essa desativação ocorre de forma estocástica. A ideia é que um neurônio não fique sempre ativado nem sempre desativado, mas que exista uma alternância. Isso força a rede a não depender excessivamente de neurônios específicos, promovendo uma maior robustez no aprendizado.\n",
        "\n",
        "Uma das dificuldades dessa técnica consiste em determinar onde aplicá-la (em quais camadas) e definir o valor adequado da probabilidade de dropout. Por isso, geralmente é necessário um tempo maior para experimentação e ajuste de hiperparâmetros.\n"
      ],
      "metadata": {
        "id": "eg-xYNR84mi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Forneça o pseudocódigo (algo em torno de 4~5 linhas) para o algoritmo de atualização de pesos com momento e descreva sucintamente seu funcionamento."
      ],
      "metadata": {
        "id": "Kti99-LC4mZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# w: peso atual\n",
        "\n",
        "# v: velocidade acumulada (momentum)\n",
        "\n",
        "# α: coeficiente de momento (0 < α < 1)\n",
        "\n",
        "# η: taxa de aprendizado\n",
        "\n",
        "# ∂E/∂w: gradiente do erro em relação ao peso w\n",
        "\n",
        "# Descrição:\n",
        "# O algoritmo de momento adiciona uma fração da atualização anterior (v) à nova atualização. Isso ajuda a suavizar o caminho do gradiente,\n",
        "#  acelerando a convergência em direções consistentes e reduzindo oscilações, especialmente em regiões com vales estreitos na superfície de erro.\n",
        "\n",
        "\n",
        "para cada peso w:\n",
        "    v = α * v - η * ∂E/∂w       # atualiza o termo do momento\n",
        "    w = w + v                   # atualiza o peso com base no momento\n"
      ],
      "metadata": {
        "id": "jQWMwGKhY4az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Descreva o funcionamento de uma camada convolucional.\n",
        "\n",
        "\n",
        "A camada convolucional é uma das partes principais de uma CNN e tem como função identificar padrões nos dados de entrada, como bordas, cores, texturas e formas. Ela faz isso aplicando pequenos filtros que percorrem a imagem ou o mapa de características recebido da camada anterior.\n",
        "\n",
        "Funcionamento Básico\n",
        "\n",
        "Entrada: A camada recebe uma matriz de dados, que pode ser a própria imagem (caso seja a primeira camada) ou um feature map vindo de outra camada.\n",
        "\n",
        "Filtros: A camada aplica filtros de tamanho fixo (como 3×3 ou 5×5) que deslizam pela matriz de entrada com um passo definido (o stride). Cada filtro é treinado para identificar um tipo de padrão.\n",
        "\n",
        "Convolução: Para cada posição onde o filtro é aplicado, os valores da região da entrada são multiplicados pelos valores do filtro e somados. Esse valor representa o quanto aquele padrão está presente naquele ponto da imagem.\n",
        "\n",
        "Geração de novos mapas: O resultado desse processo forma um novo mapa de características (feature map), que destaca onde os padrões aprendidos aparecem na imagem.\n",
        "\n",
        "Parâmetros importantes:\n",
        "\n",
        "Stride define o passo do filtro. Um stride maior reduz mais a dimensão da saída.\n",
        "\n",
        "Padding adiciona bordas com zeros ao redor da entrada, para garantir que o filtro consiga cobrir toda a imagem e preservar seu tamanho.A camada convolucional é uma das partes principais de uma CNN e tem como função identificar padrões nos dados de entrada, como bordas, cores, texturas e formas. Ela faz isso aplicando pequenos filtros (ou kernels) que percorrem a imagem ou o mapa de características recebido da camada anterior.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R2We_dns4zU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Descreva o funcionamento de uma camada de pooling."
      ],
      "metadata": {
        "id": "NeUc0dMh45C7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A camada de pooling é um componente essencial nas redes neurais convolucionais (CNNs), geralmente aplicada após as camadas convolucionais. Seu principal objetivo é reduzir a dimensionalidade espacial dos dados de entrada, mantendo as características mais relevantes, o que ajuda a diminuir o custo computacional, reduzir o risco de overfitting e extrair características invariantes a pequenas translações ou distorções.\n",
        "\n",
        "**Funcionamento Básico:**\n",
        "\n",
        "1.   **Entrada:** Recebe uma matriz de ativações (feature map) produzida por uma camada convolucional ou de pooling anterior.\n",
        "\n",
        "2.   **Operação de Pooling:** A camada divide o feature map em regiões menores, chamadas de janelas ou kernels (normalmente de tamanho fixo, como 2x2 ou 3x3), que deslizam sobre a mapa com uma certa taxa de passo (stride).\n",
        "\n",
        "3.   **Cálculo do valor de saída:** Para cada janela, a camada calcula um valor resumido baseado nos valores da região:\n",
        "\n",
        "*  **Max Pooling:** Seleciona o maior valor na janela.\n",
        "*  **Average Pooling:** Calcula a média dos valores na janela.\n",
        "*  **Outros métodos:** Como Pooling p-norm, ou métodos mais complexos, porém max e average são os mais comuns.\n",
        "\n",
        "4. **Saída:** A matriz resultante é menor que a entrada, contendo os valores resumidos de cada janela, formando um novo mapa de características.\n",
        "\n",
        "**Exemplo de Max Pooling 2x2 com stride 2:**\n",
        "\n",
        "Se temos uma matriz de entrada 4x4, o max pooling 2x2 com stride 2 irá dividir essa matriz em quatro regiões 2x2 e selecionar o valor máximo de cada uma, resultando em uma matriz 2x2 de valores resumidos."
      ],
      "metadata": {
        "id": "J6FtsCvzEITy"
      }
    }
  ]
}